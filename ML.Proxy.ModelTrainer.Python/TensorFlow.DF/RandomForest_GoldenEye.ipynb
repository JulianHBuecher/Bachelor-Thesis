{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###############################################################################\n",
    "# Random Forest Classification Model (TensorFlow)                             #\n",
    "# Based on the Implementation of:                                             #\n",
    "# For GoldenEye Dataset                                                       #\n",
    "# https://www.tensorflow.org/decision_forests/tutorials/beginner_colab        #\n",
    "###############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: pandas in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (1.2.5)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from pandas) (1.19.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: tensorflow_decision_forests in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (0.1.7)\n",
      "Requirement already satisfied: wheel in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from tensorflow_decision_forests) (0.36.2)\n",
      "Requirement already satisfied: six in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from tensorflow_decision_forests) (1.15.0)\n",
      "Requirement already satisfied: numpy in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from tensorflow_decision_forests) (1.19.2)\n",
      "Requirement already satisfied: tensorflow~=2.5 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from tensorflow_decision_forests) (2.5.0)\n",
      "Requirement already satisfied: absl-py in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from tensorflow_decision_forests) (0.13.0)\n",
      "Requirement already satisfied: pandas in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from tensorflow_decision_forests) (1.2.5)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from tensorflow~=2.5->tensorflow_decision_forests) (3.7.4.3)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from tensorflow~=2.5->tensorflow_decision_forests) (1.12.1)\n",
      "Requirement already satisfied: keras-nightly~=2.5.0.dev in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from tensorflow~=2.5->tensorflow_decision_forests) (2.5.0.dev2021032900)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from tensorflow~=2.5->tensorflow_decision_forests) (1.6.3)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from tensorflow~=2.5->tensorflow_decision_forests) (3.3.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from tensorflow~=2.5->tensorflow_decision_forests) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from tensorflow~=2.5->tensorflow_decision_forests) (2.5.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from tensorflow~=2.5->tensorflow_decision_forests) (1.12)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from tensorflow~=2.5->tensorflow_decision_forests) (3.17.3)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from tensorflow~=2.5->tensorflow_decision_forests) (3.1.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from tensorflow~=2.5->tensorflow_decision_forests) (0.2.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from tensorflow~=2.5->tensorflow_decision_forests) (1.1.2)\n",
      "Requirement already satisfied: grpcio~=1.34.0 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from tensorflow~=2.5->tensorflow_decision_forests) (1.34.1)\n",
      "Requirement already satisfied: gast==0.4.0 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from tensorflow~=2.5->tensorflow_decision_forests) (0.4.0)\n",
      "Requirement already satisfied: tensorboard~=2.5 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from tensorflow~=2.5->tensorflow_decision_forests) (2.5.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from pandas->tensorflow_decision_forests) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from pandas->tensorflow_decision_forests) (2.8.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (1.8.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (1.32.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (2.25.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (44.0.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (2.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (0.4.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (0.6.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (4.7.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (2021.5.30)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (1.26.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (2.10)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (3.1.1)\n",
      "Requirement already satisfied: wurlitzer in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (2.1.0)\n",
      "Requirement already satisfied: matplotlib in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (3.4.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from matplotlib) (8.2.0)\n",
      "Requirement already satisfied: numpy>=1.16 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from matplotlib) (1.19.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: six in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "Requirement already satisfied: ipython in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (7.24.1)\n",
      "Requirement already satisfied: pygments in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from ipython) (2.9.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from ipython) (0.18.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from ipython) (3.0.19)\n",
      "Requirement already satisfied: pickleshare in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from ipython) (0.7.5)\n",
      "Requirement already satisfied: backcall in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from ipython) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from ipython) (0.1.2)\n",
      "Requirement already satisfied: pexpect>4.3; sys_platform != \"win32\" in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from ipython) (4.8.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from ipython) (5.0.5)\n",
      "Requirement already satisfied: decorator in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from ipython) (5.0.9)\n",
      "Requirement already satisfied: setuptools>=18.5 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from ipython) (44.0.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from jedi>=0.16->ipython) (0.8.2)\n",
      "Requirement already satisfied: wcwidth in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython) (0.2.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from pexpect>4.3; sys_platform != \"win32\"->ipython) (0.7.0)\n",
      "Requirement already satisfied: ipython-genutils in /home/julianbuecher/Projects/Bachelor-Thesis/ML.Proxy.ModelTrainer.Python/lib/python3.8/site-packages (from traitlets>=4.2->ipython) (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "# Installieren aller benötigten Pakete\n",
    "!pip install pandas\n",
    "!pip install tensorflow_decision_forests\n",
    "!pip install wurlitzer\n",
    "!pip install matplotlib\n",
    "!pip install ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden der benötigten Python Pakete\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow_decision_forests as tfdf\n",
    "from wurlitzer import sys_pipes\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found TensorFlow Decision Forests v0.1.7\n"
     ]
    }
   ],
   "source": [
    "# Prüfung der installierten TensorFlow Decision Forests Version\n",
    "print(f\"Found TensorFlow Decision Forests v{tfdf.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden der Netzwerk Traffic Daten für den GoldenEye Angriff\n",
    "data_GoldenEye = pd.read_csv('../Data/Thursday-15-02-2018_GoldenEye-Attack.csv')\n",
    "# Umbenennen der einzelnen Spalte für eine bessere Kompatibilität mit TensorFlow\n",
    "data_GoldenEye.rename(columns={\n",
    "    'Bwd Pkt Len Std':'bwd_pkt_len_std',\n",
    "    'Flow IAT Min':'flow_iat_min',\n",
    "    'Fwd IAT Min':'fwd_iat_min',\n",
    "    'Flow IAT Mean':'flow_iat_mean',\n",
    "    'Label':'label'\n",
    "},\n",
    "inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Festlegen des Wertes der bestimmten Variable\n",
    "label = 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "726193 examples in training, 311392 examples for testing.\n"
     ]
    }
   ],
   "source": [
    "# Aufteilen des Datasets in Training- und Test-Daten\n",
    "def split_dataset(dataset,  test_ratio=0.30):\n",
    "    \"\"\"Splits a panda dataframe in two dataframes.\"\"\"\n",
    "    test_indices = np.random.rand(len(dataset)) < test_ratio\n",
    "    return dataset[~test_indices], dataset[test_indices]\n",
    "\n",
    "training_data_GoldenEye, testing_data_GoldenEye = split_dataset(data_GoldenEye)\n",
    "\n",
    "print(\"{} examples in training, {} examples for testing.\".format(\n",
    "    len(training_data_GoldenEye), len(testing_data_GoldenEye)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Converting Panda Dataframe into TensorFlow Dataset...\n"
     ]
    }
   ],
   "source": [
    "# Konvertieren des Panda Dataframes in ein TensorFlow Dataset\n",
    "print(\"Converting Panda Dataframe into TensorFlow Dataset...\")\n",
    "training_dataset_GoldenEye = tfdf.keras.pd_dataframe_to_tf_dataset(training_data_GoldenEye, label=label)\n",
    "testing_dataset_GoldenEye = tfdf.keras.pd_dataframe_to_tf_dataset(testing_data_GoldenEye, label=label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellen des Random Forest Modells\n",
    "model = tfdf.keras.RandomForestModel()\n",
    "model.compile(metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training the Model: \n",
      "2021-06-28 10:19:37.125291: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-06-28 10:19:37.150848: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2199995000 Hz\n",
      "11347/11347 [==============================] - 11s 738us/step\n",
      "[INFO kernel.cc:746] Start Yggdrasil model training\n",
      "[INFO kernel.cc:747] Collect training examples\n",
      "[INFO kernel.cc:392] Number of batches: 11347\n",
      "[INFO kernel.cc:393] Number of examples: 726193\n",
      "[INFO kernel.cc:769] Dataset:\n",
      "Number of records: 726193\n",
      "Number of columns: 5\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 4 (80%)\n",
      "\tCATEGORICAL: 1 (20%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 4 (80%)\n",
      "\t0: \"bwd_pkt_len_std\" NUMERICAL mean:121.772 min:0 max:931.26 sd:207.567\n",
      "\t1: \"flow_iat_mean\" NUMERICAL mean:2.9511e+06 min:0 max:1.19992e+08 sd:1.12061e+07\n",
      "\t2: \"flow_iat_min\" NUMERICAL mean:2.37826e+06 min:0 max:1.19992e+08 sd:1.10505e+07\n",
      "\t3: \"fwd_iat_min\" NUMERICAL mean:2.55799e+06 min:0 max:1.19992e+08 sd:1.15639e+07\n",
      "\n",
      "CATEGORICAL: 1 (20%)\n",
      "\t4: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO kernel.cc:772] Configure learner\n",
      "[INFO kernel.cc:797] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"bwd_pkt_len_std\"\n",
      "features: \"flow_iat_mean\"\n",
      "features: \"flow_iat_min\"\n",
      "features: \"fwd_iat_min\"\n",
      "label: \"__LABEL\"\n",
      "task: CLASSIFICATION\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 16\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    num_candidate_attributes_ratio: -1\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "}\n",
      "\n",
      "[INFO kernel.cc:800] Deployment config:\n",
      "\n",
      "[INFO kernel.cc:837] Train model\n",
      "[INFO random_forest.cc:303] Training random forest on 726193 example(s) and 4 feature(s).\n",
      "[INFO random_forest.cc:578] Training of tree  1/300 (tree index:5) done accuracy:0.998449 logloss:0.0559045\n",
      "[INFO random_forest.cc:578] Training of tree  11/300 (tree index:10) done accuracy:0.998617 logloss:0.028687\n",
      "[INFO random_forest.cc:578] Training of tree  21/300 (tree index:19) done accuracy:0.998712 logloss:0.0214437\n",
      "[INFO random_forest.cc:578] Training of tree  31/300 (tree index:30) done accuracy:0.998757 logloss:0.018781\n",
      "[INFO random_forest.cc:578] Training of tree  41/300 (tree index:41) done accuracy:0.998748 logloss:0.0175529\n",
      "[INFO random_forest.cc:578] Training of tree  51/300 (tree index:51) done accuracy:0.998725 logloss:0.0168427\n",
      "[INFO random_forest.cc:578] Training of tree  61/300 (tree index:60) done accuracy:0.998736 logloss:0.0162781\n",
      "[INFO random_forest.cc:578] Training of tree  71/300 (tree index:70) done accuracy:0.998757 logloss:0.0159545\n",
      "[INFO random_forest.cc:578] Training of tree  81/300 (tree index:77) done accuracy:0.998752 logloss:0.0158182\n",
      "[INFO random_forest.cc:578] Training of tree  91/300 (tree index:90) done accuracy:0.998758 logloss:0.015413\n",
      "[INFO random_forest.cc:578] Training of tree  101/300 (tree index:100) done accuracy:0.998762 logloss:0.0151109\n",
      "[INFO random_forest.cc:578] Training of tree  111/300 (tree index:110) done accuracy:0.998774 logloss:0.0146609\n",
      "[INFO random_forest.cc:578] Training of tree  121/300 (tree index:120) done accuracy:0.998762 logloss:0.0142258\n",
      "[INFO random_forest.cc:578] Training of tree  131/300 (tree index:130) done accuracy:0.998769 logloss:0.0140478\n",
      "[INFO random_forest.cc:578] Training of tree  141/300 (tree index:140) done accuracy:0.99878 logloss:0.013911\n",
      "[INFO random_forest.cc:578] Training of tree  151/300 (tree index:150) done accuracy:0.998773 logloss:0.0138197\n",
      "[INFO random_forest.cc:578] Training of tree  161/300 (tree index:160) done accuracy:0.99877 logloss:0.0135554\n",
      "[INFO random_forest.cc:578] Training of tree  171/300 (tree index:170) done accuracy:0.998766 logloss:0.0133865\n",
      "[INFO random_forest.cc:578] Training of tree  181/300 (tree index:180) done accuracy:0.998761 logloss:0.0132982\n",
      "[INFO random_forest.cc:578] Training of tree  191/300 (tree index:192) done accuracy:0.998761 logloss:0.0131585\n",
      "[INFO random_forest.cc:578] Training of tree  201/300 (tree index:199) done accuracy:0.998763 logloss:0.0131085\n",
      "[INFO random_forest.cc:578] Training of tree  211/300 (tree index:211) done accuracy:0.998757 logloss:0.0129832\n",
      "[INFO random_forest.cc:578] Training of tree  221/300 (tree index:220) done accuracy:0.998761 logloss:0.012893\n",
      "[INFO random_forest.cc:578] Training of tree  231/300 (tree index:230) done accuracy:0.998762 logloss:0.012805\n",
      "[INFO random_forest.cc:578] Training of tree  241/300 (tree index:241) done accuracy:0.998762 logloss:0.0128019\n",
      "[INFO random_forest.cc:578] Training of tree  251/300 (tree index:250) done accuracy:0.998758 logloss:0.012632\n",
      "[INFO random_forest.cc:578] Training of tree  261/300 (tree index:260) done accuracy:0.998761 logloss:0.0125415\n",
      "[INFO random_forest.cc:578] Training of tree  271/300 (tree index:270) done accuracy:0.998759 logloss:0.0125395\n",
      "[INFO random_forest.cc:578] Training of tree  281/300 (tree index:280) done accuracy:0.998759 logloss:0.0125021\n",
      "[INFO random_forest.cc:578] Training of tree  291/300 (tree index:290) done accuracy:0.998758 logloss:0.0124639\n",
      "[INFO random_forest.cc:578] Training of tree  300/300 (tree index:299) done accuracy:0.998759 logloss:0.0124152\n",
      "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.998759 logloss:0.0124152\n",
      "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpufszd98k\n",
      "[INFO kernel.cc:864] Save model in resources\n",
      "[INFO kernel.cc:960] Loading model from path\n",
      "[INFO decision_forest.cc:590] Model loaded with 300 root(s), 289482 node(s), and 4 input feature(s).\n",
      "[INFO abstract_model.cc:973] Engine \"RandomForestOptPred\" built\n",
      "[INFO kernel.cc:820] Use fast generic engine\n"
     ]
    }
   ],
   "source": [
    "# Trainieren des Modells\n",
    "print(\"Training the Model: \")\n",
    "with sys_pipes():\n",
    "    model.fit(x=training_dataset_GoldenEye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Evaluating the Model...\n",
      "4866/4866 [==============================] - 14s 3ms/step - loss: 0.0000e+00 - accuracy: 0.9987\n",
      "\n",
      "loss: 0.0000\n",
      "accuracy: 0.9987\n"
     ]
    }
   ],
   "source": [
    "# Evaluation des trainierten Modells mit den Testdaten\n",
    "print(\"Evaluating the Model...\")\n",
    "evaluation = model.evaluate(testing_dataset_GoldenEye, return_dict=True)\n",
    "\n",
    "print()\n",
    "\n",
    "for name, value in evaluation.items():\n",
    "    print(f\"{name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Assets written to: ../Data/Models/goldeneye_model/assets\n",
      "INFO:tensorflow:Assets written to: ../Data/Models/goldeneye_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Trainiertes Modell für die spätere Verwendung abspeichern\n",
    "model.save(\"../Data/Models/goldeneye_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\n<script src=\"https://d3js.org/d3.v6.min.js\"></script>\\n<div id=\"tree_plot_719bfc1645154bf9a09a4add8f6df17e\"></div>\\n<script>\\n/*\\n * Copyright 2021 Google LLC.\\n * Licensed under the Apache License, Version 2.0 (the \"License\");\\n * you may not use this file except in compliance with the License.\\n * You may obtain a copy of the License at\\n *\\n *     https://www.apache.org/licenses/LICENSE-2.0\\n *\\n * Unless required by applicable law or agreed to in writing, software\\n * distributed under the License is distributed on an \"AS IS\" BASIS,\\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\n * See the License for the specific language governing permissions and\\n * limitations under the License.\\n */\\n\\n/**\\n *  Plotting of decision trees generated by TF-DF.\\n *\\n *  A tree is a recursive structure of node objects.\\n *  A node contains one or more of the following components:\\n *\\n *    - A value: Representing the output of the node. If the node is not a leaf,\\n *      the value is only present for analysis i.e. it is not used for\\n *      predictions.\\n *\\n *    - A condition : For non-leaf nodes, the condition (also known as split)\\n *      defines a binary test to branch to the positive or negative child.\\n *\\n *    - An explanation: Generally a plot showing the relation between the label\\n *      and the condition to give insights about the effect of the condition.\\n *\\n *    - Two children : For non-leaf nodes, the children nodes. The first\\n *      children (i.e. \"node.children[0]\") is the negative children (drawn in\\n *      red). The second children is the positive one (drawn in green).\\n *\\n */\\n\\n/**\\n * Plots a single decision tree into a DOM element.\\n * @param {!options} options Dictionary of configurations.\\n * @param {!tree} raw_tree Recursive tree structure.\\n * @param {string} canvas_id Id of the output dom element.\\n */\\nfunction display_tree(options, raw_tree, canvas_id) {\\n  console.log(options);\\n\\n  // Determine the node placement.\\n  const tree_struct = d3.tree().nodeSize(\\n      [options.node_y_offset, options.node_x_offset])(d3.hierarchy(raw_tree));\\n\\n  // Boundaries of the node placement.\\n  let x_min = Infinity;\\n  let x_max = -x_min;\\n  let y_min = Infinity;\\n  let y_max = -x_min;\\n\\n  tree_struct.each(d => {\\n    if (d.x > x_max) x_max = d.x;\\n    if (d.x < x_min) x_min = d.x;\\n    if (d.y > y_max) y_max = d.y;\\n    if (d.y < y_min) y_min = d.y;\\n  });\\n\\n  // Size of the plot.\\n  const width = y_max - y_min + options.node_x_size + options.margin * 2;\\n  const height = x_max - x_min + options.node_y_size + options.margin * 2 +\\n      options.node_y_offset - options.node_y_size;\\n\\n  const plot = d3.select(canvas_id);\\n\\n  // Tool tip\\n  options.tooltip = plot.append(\\'div\\')\\n                        .attr(\\'width\\', 100)\\n                        .attr(\\'height\\', 100)\\n                        .style(\\'padding\\', \\'4px\\')\\n                        .style(\\'background\\', \\'#fff\\')\\n                        .style(\\'box-shadow\\', \\'4px 4px 0px rgba(0,0,0,0.1)\\')\\n                        .style(\\'border\\', \\'1px solid black\\')\\n                        .style(\\'font-family\\', \\'sans-serif\\')\\n                        .style(\\'font-size\\', options.font_size)\\n                        .style(\\'position\\', \\'absolute\\')\\n                        .style(\\'z-index\\', \\'10\\')\\n                        .attr(\\'pointer-events\\', \\'none\\')\\n                        .style(\\'display\\', \\'none\\');\\n\\n  // Create canvas\\n  const svg = plot.append(\\'svg\\').attr(\\'width\\', width).attr(\\'height\\', height);\\n  const graph =\\n      svg.style(\\'overflow\\', \\'visible\\')\\n          .append(\\'g\\')\\n          .attr(\\'font-family\\', \\'sans-serif\\')\\n          .attr(\\'font-size\\', options.font_size)\\n          .attr(\\n              \\'transform\\',\\n              () => `translate(${options.margin},${\\n                  - x_min + options.node_y_offset / 2 + options.margin})`);\\n\\n  // Plot bounding box.\\n  if (options.show_plot_bounding_box) {\\n    svg.append(\\'rect\\')\\n        .attr(\\'width\\', width)\\n        .attr(\\'height\\', height)\\n        .attr(\\'fill\\', \\'none\\')\\n        .attr(\\'stroke-width\\', 1.0)\\n        .attr(\\'stroke\\', \\'black\\');\\n  }\\n\\n  // Draw the edges.\\n  display_edges(options, graph, tree_struct);\\n\\n  // Draw the nodes.\\n  display_nodes(options, graph, tree_struct);\\n}\\n\\n/**\\n * Draw the nodes of the tree.\\n * @param {!options} options Dictionary of configurations.\\n * @param {!graph} graph D3 search handle containing the graph.\\n * @param {!tree_struct} tree_struct Structure of the tree (node placement,\\n *     data, etc.).\\n */\\nfunction display_nodes(options, graph, tree_struct) {\\n  const nodes = graph.append(\\'g\\')\\n                    .selectAll(\\'g\\')\\n                    .data(tree_struct.descendants())\\n                    .join(\\'g\\')\\n                    .attr(\\'transform\\', d => `translate(${d.y},${d.x})`);\\n\\n  nodes.append(\\'rect\\')\\n      .attr(\\'x\\', 0.5)\\n      .attr(\\'y\\', 0.5)\\n      .attr(\\'width\\', options.node_x_size)\\n      .attr(\\'height\\', options.node_y_size)\\n      .attr(\\'stroke\\', \\'lightgrey\\')\\n      .attr(\\'stroke-width\\', 1)\\n      .attr(\\'fill\\', \\'white\\')\\n      .attr(\\'y\\', -options.node_y_size / 2);\\n\\n  // Brackets on the right of condition nodes without children.\\n  non_leaf_node_without_children =\\n      nodes.filter(node => node.data.condition != null && node.children == null)\\n          .append(\\'g\\')\\n          .attr(\\'transform\\', `translate(${options.node_x_size},0)`);\\n\\n  non_leaf_node_without_children.append(\\'path\\')\\n      .attr(\\'d\\', \\'M0,0 C 10,0 0,10 10,10\\')\\n      .attr(\\'fill\\', \\'none\\')\\n      .attr(\\'stroke-width\\', 1.0)\\n      .attr(\\'stroke\\', \\'#F00\\');\\n\\n  non_leaf_node_without_children.append(\\'path\\')\\n      .attr(\\'d\\', \\'M0,0 C 10,0 0,-10 10,-10\\')\\n      .attr(\\'fill\\', \\'none\\')\\n      .attr(\\'stroke-width\\', 1.0)\\n      .attr(\\'stroke\\', \\'#0F0\\');\\n\\n  const node_content = nodes.append(\\'g\\').attr(\\n      \\'transform\\',\\n      `translate(0,${options.node_padding - options.node_y_size / 2})`);\\n\\n  node_content.append(node => create_node_element(options, node));\\n}\\n\\n/**\\n * Creates the D3 content for a single node.\\n * @param {!options} options Dictionary of configurations.\\n * @param {!node} node Node to draw.\\n * @return {!d3} D3 content.\\n */\\nfunction create_node_element(options, node) {\\n  // Output accumulator.\\n  let output = {\\n    // Content to draw.\\n    content: d3.create(\\'svg:g\\'),\\n    // Vertical offset to the next element to draw.\\n    vertical_offset: 0\\n  };\\n\\n  // Conditions.\\n  if (node.data.condition != null) {\\n    display_condition(options, node.data.condition, output);\\n  }\\n\\n  // Values.\\n  if (node.data.value != null) {\\n    display_value(options, node.data.value, output);\\n  }\\n\\n  // Explanations.\\n  if (node.data.explanation != null) {\\n    display_explanation(options, node.data.explanation, output);\\n  }\\n\\n  return output.content.node();\\n}\\n\\n\\n/**\\n * Adds a single line of text inside of a node.\\n * @param {!options} options Dictionary of configurations.\\n * @param {string} text Text to display.\\n * @param {!output} output Output display accumulator.\\n */\\nfunction display_node_text(options, text, output) {\\n  output.content.append(\\'text\\')\\n      .attr(\\'x\\', options.node_padding)\\n      .attr(\\'y\\', output.vertical_offset)\\n      .attr(\\'alignment-baseline\\', \\'hanging\\')\\n      .text(text);\\n  output.vertical_offset += 10;\\n}\\n\\n/**\\n * Adds a single line of text inside of a node with a tooltip.\\n * @param {!options} options Dictionary of configurations.\\n * @param {string} text Text to display.\\n * @param {string} tooltip Text in the Tooltip.\\n * @param {!output} output Output display accumulator.\\n */\\nfunction display_node_text_with_tooltip(options, text, tooltip, output) {\\n  const item = output.content.append(\\'text\\')\\n                   .attr(\\'x\\', options.node_padding)\\n                   .attr(\\'alignment-baseline\\', \\'hanging\\')\\n                   .text(text);\\n\\n  add_tooltip(options, item, () => tooltip);\\n  output.vertical_offset += 10;\\n}\\n\\n/**\\n * Adds a tooltip to a dom element.\\n * @param {!options} options Dictionary of configurations.\\n * @param {!dom} target Dom element to equip with a tooltip.\\n * @param {!func} get_content Generates the html content of the tooltip.\\n */\\nfunction add_tooltip(options, target, get_content) {\\n  function show(d) {\\n    options.tooltip.style(\\'display\\', \\'block\\');\\n    options.tooltip.html(get_content());\\n  }\\n\\n  function hide(d) {\\n    options.tooltip.style(\\'display\\', \\'none\\');\\n  }\\n\\n  function move(d) {\\n    options.tooltip.style(\\'display\\', \\'block\\');\\n    options.tooltip.style(\\'left\\', (d.pageX + 5) + \\'px\\');\\n    options.tooltip.style(\\'top\\', d.pageY + \\'px\\');\\n  }\\n\\n  target.on(\\'mouseover\\', show);\\n  target.on(\\'mouseout\\', hide);\\n  target.on(\\'mousemove\\', move);\\n}\\n\\n/**\\n * Adds a condition inside of a node.\\n * @param {!options} options Dictionary of configurations.\\n * @param {!condition} condition Condition to display.\\n * @param {!output} output Output display accumulator.\\n */\\nfunction display_condition(options, condition, output) {\\n  threshold_format = d3.format(\\'r\\');\\n\\n  if (condition.type === \\'IS_MISSING\\') {\\n    display_node_text(options, `${condition.attribute} is missing`, output);\\n    return;\\n  }\\n\\n  if (condition.type === \\'IS_TRUE\\') {\\n    display_node_text(options, `${condition.attribute} is true`, output);\\n    return;\\n  }\\n\\n  if (condition.type === \\'NUMERICAL_IS_HIGHER_THAN\\') {\\n    format = d3.format(\\'r\\');\\n    display_node_text(\\n        options,\\n        `${condition.attribute} >= ${threshold_format(condition.threshold)}`,\\n        output);\\n    return;\\n  }\\n\\n  if (condition.type === \\'CATEGORICAL_IS_IN\\') {\\n    display_node_text_with_tooltip(\\n        options, `${condition.attribute} in [...]`,\\n        `${condition.attribute} in [${condition.mask}]`, output);\\n    return;\\n  }\\n\\n  if (condition.type === \\'CATEGORICAL_SET_CONTAINS\\') {\\n    display_node_text_with_tooltip(\\n        options, `${condition.attribute} intersect [...]`,\\n        `${condition.attribute} intersect [${condition.mask}]`, output);\\n    return;\\n  }\\n\\n  if (condition.type === \\'NUMERICAL_SPARSE_OBLIQUE\\') {\\n    display_node_text_with_tooltip(\\n        options, `Sparse oblique split...`,\\n        `[${condition.attributes}]*[${condition.weights}]>=${\\n            threshold_format(condition.threshold)}`,\\n        output);\\n    return;\\n  }\\n\\n  display_node_text(\\n      options, `Non supported condition ${condition.type}`, output);\\n}\\n\\n/**\\n * Adds a value inside of a node.\\n * @param {!options} options Dictionary of configurations.\\n * @param {!value} value Value to display.\\n * @param {!output} output Output display accumulator.\\n */\\nfunction display_value(options, value, output) {\\n  if (value.type === \\'PROBABILITY\\') {\\n    const left_margin = 0;\\n    const right_margin = 50;\\n    const plot_width = options.node_x_size - options.node_padding * 2 -\\n        left_margin - right_margin;\\n\\n    let cusum = Array.from(d3.cumsum(value.distribution));\\n    cusum.unshift(0);\\n    const distribution_plot = output.content.append(\\'g\\').attr(\\n        \\'transform\\', `translate(0,${output.vertical_offset + 0.5})`);\\n\\n    distribution_plot.selectAll(\\'rect\\')\\n        .data(value.distribution)\\n        .join(\\'rect\\')\\n        .attr(\\'height\\', 10)\\n        .attr(\\n            \\'x\\',\\n            (d, i) =>\\n                (cusum[i] * plot_width + left_margin + options.node_padding))\\n        .attr(\\'width\\', (d, i) => d * plot_width)\\n        .style(\\'fill\\', (d, i) => d3.schemeSet1[i]);\\n\\n    const num_examples =\\n        output.content.append(\\'g\\')\\n            .attr(\\'transform\\', `translate(0,${output.vertical_offset})`)\\n            .append(\\'text\\')\\n            .attr(\\'x\\', options.node_x_size - options.node_padding)\\n            .attr(\\'alignment-baseline\\', \\'hanging\\')\\n            .attr(\\'text-anchor\\', \\'end\\')\\n            .text(`(${value.num_examples})`);\\n\\n    const distribution_details = d3.create(\\'ul\\');\\n    distribution_details.selectAll(\\'li\\')\\n        .data(value.distribution)\\n        .join(\\'li\\')\\n        .append(\\'span\\')\\n        .text(\\n            (d, i) =>\\n                \\'class \\' + i + \\': \\' + d3.format(\\'.3%\\')(value.distribution[i]));\\n\\n    add_tooltip(options, distribution_plot, () => distribution_details.html());\\n    add_tooltip(options, num_examples, () => \\'Number of examples\\');\\n\\n    output.vertical_offset += 10;\\n    return;\\n  }\\n\\n  if (value.type === \\'REGRESSION\\') {\\n    display_node_text(\\n        options,\\n        \\'value: \\' + d3.format(\\'r\\')(value.value) + ` (` +\\n            d3.format(\\'.6\\')(value.num_examples) + `)`,\\n        output);\\n    return;\\n  }\\n\\n  display_node_text(options, `Non supported value ${value.type}`, output);\\n}\\n\\n/**\\n * Adds an explanation inside of a node.\\n * @param {!options} options Dictionary of configurations.\\n * @param {!explanation} explanation Explanation to display.\\n * @param {!output} output Output display accumulator.\\n */\\nfunction display_explanation(options, explanation, output) {\\n  // Margin before the explanation.\\n  output.vertical_offset += 10;\\n\\n  display_node_text(\\n      options, `Non supported explanation ${explanation.type}`, output);\\n}\\n\\n\\n/**\\n * Draw the edges of the tree.\\n * @param {!options} options Dictionary of configurations.\\n * @param {!graph} graph D3 search handle containing the graph.\\n * @param {!tree_struct} tree_struct Structure of the tree (node placement,\\n *     data, etc.).\\n */\\nfunction display_edges(options, graph, tree_struct) {\\n  // Draw an edge between a parent and a child node with a bezier.\\n  function draw_single_edge(d) {\\n    return \\'M\\' + (d.source.y + options.node_x_size) + \\',\\' + d.source.x + \\' C\\' +\\n        (d.source.y + options.node_x_size + options.edge_rounding) + \\',\\' +\\n        d.source.x + \\' \\' + (d.target.y - options.edge_rounding) + \\',\\' +\\n        d.target.x + \\' \\' + d.target.y + \\',\\' + d.target.x;\\n  }\\n\\n  graph.append(\\'g\\')\\n      .attr(\\'fill\\', \\'none\\')\\n      .attr(\\'stroke-width\\', 1.2)\\n      .selectAll(\\'path\\')\\n      .data(tree_struct.links())\\n      .join(\\'path\\')\\n      .attr(\\'d\\', draw_single_edge)\\n      .attr(\\n          \\'stroke\\', d => (d.target === d.source.children[0]) ? \\'#0F0\\' : \\'#F00\\');\\n}\\n\\ndisplay_tree({\"margin\": 10, \"node_x_size\": 160, \"node_y_size\": 28, \"node_x_offset\": 180, \"node_y_offset\": 33, \"font_size\": 10, \"edge_rounding\": 20, \"node_padding\": 2, \"show_plot_bounding_box\": false}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.960441645678215, 0.03955835432178498], \"num_examples\": 726193.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"flow_iat_mean\", \"threshold\": 605984.75}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.8471516971782841, 0.15284830282171594], \"num_examples\": 171137.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"flow_iat_min\", \"threshold\": 2.5}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.7972582044935875, 0.20274179550641253], \"num_examples\": 124444.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"bwd_pkt_len_std\", \"threshold\": 330.9661865234375}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.3231720593999042, 0.6768279406000958], \"num_examples\": 22963.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"flow_iat_min\", \"threshold\": 8.5}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.9045338536277727, 0.09546614637222732], \"num_examples\": 101481.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"flow_iat_min\", \"threshold\": 1358967.0}}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.9801255006103698, 0.019874499389630138], \"num_examples\": 46693.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"fwd_iat_min\", \"threshold\": 53238112.0}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.0, 1.0], \"num_examples\": 486.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.9904343497738438, 0.00956565022615621], \"num_examples\": 46207.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"flow_iat_min\", \"threshold\": 1.5}}]}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.9953716381770488, 0.004628361822951198], \"num_examples\": 555056.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"bwd_pkt_len_std\", \"threshold\": 382.1197814941406}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.9646823480720149, 0.0353176519279851], \"num_examples\": 72485.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"flow_iat_mean\", \"threshold\": 70913.4296875}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.9929804415468958, 0.007019558453104164], \"num_examples\": 53992.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"fwd_iat_min\", \"threshold\": 230.5}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.8820634834802358, 0.11793651651976424], \"num_examples\": 18493.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"flow_iat_min\", \"threshold\": 2.5}}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.999981349894627, 1.8650105373095357e-05], \"num_examples\": 482571.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"flow_iat_mean\", \"threshold\": 464634.125}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.9968971631205674, 0.0031028368794326243], \"num_examples\": 2256.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"flow_iat_mean\", \"threshold\": 464997.8125}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.999995836065915, 4.163934084923436e-06], \"num_examples\": 480315.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"fwd_iat_min\", \"threshold\": 49688.5}}]}]}]}, \"#tree_plot_719bfc1645154bf9a09a4add8f6df17e\")\\n</script>\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "# Plotten des ersten Baumes innerhalb des Decision Forests\n",
    "with open('../Data/Models/GoldenEye_Model_Tree.html', 'w') as f:\n",
    "    f.write(tfdf.model_plotter.plot_model(model, tree_idx=0, max_depth=3))\n",
    "tfdf.model_plotter.plot_model(model, tree_idx=0, max_depth=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"random_forest_model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nTotal params: 1\nTrainable params: 0\nNon-trainable params: 1\n_________________________________________________________________\nType: \"RANDOM_FOREST\"\nTask: CLASSIFICATION\nLabel: \"__LABEL\"\n\nInput Features (4):\n\tbwd_pkt_len_std\n\tflow_iat_mean\n\tflow_iat_min\n\tfwd_iat_min\n\nNo weights\n\nVariable Importance: NUM_NODES:\n    1.   \"flow_iat_mean\" 46522.000000 ################\n    2.     \"fwd_iat_min\" 39806.000000 ###########\n    3.    \"flow_iat_min\" 38528.000000 ###########\n    4. \"bwd_pkt_len_std\" 19735.000000 \n\nVariable Importance: NUM_AS_ROOT:\n    1.   \"flow_iat_mean\" 233.000000 ################\n    2.     \"fwd_iat_min\" 41.000000 #\n    3. \"bwd_pkt_len_std\" 26.000000 \n\nVariable Importance: SUM_SCORE:\n    1.   \"flow_iat_mean\" 13141977.443992 ################\n    2.    \"flow_iat_min\" 10991524.746150 ############\n    3. \"bwd_pkt_len_std\" 7479945.217989 #####\n    4.     \"fwd_iat_min\" 4479344.495716 \n\nVariable Importance: MEAN_MIN_DEPTH:\n    1.         \"__LABEL\" 11.916983 ################\n    2. \"bwd_pkt_len_std\"  5.296940 ######\n    3.     \"fwd_iat_min\"  3.669541 ####\n    4.    \"flow_iat_min\"  2.917503 ###\n    5.   \"flow_iat_mean\"  0.498021 \n\n\n\nWinner take all: true\nOut-of-bag evaluation: accuracy:0.998759 logloss:0.0124152\nNumber of trees: 300\nTotal number of nodes: 289482\n\nNumber of nodes by tree:\nCount: 300 Average: 964.94 StdDev: 74.3538\nMin: 693 Max: 1153 Ignored: 0\n----------------------------------------------\n[  693,  716)  2   0.67%   0.67%\n[  716,  739)  0   0.00%   0.67%\n[  739,  762)  1   0.33%   1.00%\n[  762,  785)  3   1.00%   2.00% #\n[  785,  808)  5   1.67%   3.67% #\n[  808,  831)  4   1.33%   5.00% #\n[  831,  854) 10   3.33%   8.33% ##\n[  854,  877) 10   3.33%  11.67% ##\n[  877,  900) 16   5.33%  17.00% ####\n[  900,  923) 24   8.00%  25.00% ######\n[  923,  946) 25   8.33%  33.33% ######\n[  946,  969) 36  12.00%  45.33% ########\n[  969,  992) 43  14.33%  59.67% ##########\n[  992, 1015) 43  14.33%  74.00% ##########\n[ 1015, 1038) 38  12.67%  86.67% #########\n[ 1038, 1061) 18   6.00%  92.67% ####\n[ 1061, 1084) 14   4.67%  97.33% ###\n[ 1084, 1107)  5   1.67%  99.00% #\n[ 1107, 1130)  1   0.33%  99.33%\n[ 1130, 1153]  2   0.67% 100.00%\n\nDepth by leafs:\nCount: 144891 Average: 11.914 StdDev: 2.67573\nMin: 2 Max: 15 Ignored: 0\n----------------------------------------------\n[  2,  3)    23   0.02%   0.02%\n[  3,  4)   107   0.07%   0.09%\n[  4,  5)   669   0.46%   0.55%\n[  5,  6)  2325   1.60%   2.16% #\n[  6,  7)  3692   2.55%   4.70% #\n[  7,  8)  4648   3.21%   7.91% ##\n[  8,  9)  6419   4.43%  12.34% ##\n[  9, 10)  9203   6.35%  18.69% ###\n[ 10, 11) 12673   8.75%  27.44% ####\n[ 11, 12) 15873  10.96%  38.40% #####\n[ 12, 13) 18794  12.97%  51.37% ######\n[ 13, 14) 20520  14.16%  65.53% #######\n[ 14, 15) 20103  13.87%  79.40% #######\n[ 15, 15] 29842  20.60% 100.00% ##########\n\nNumber of training obs by leaf:\nCount: 144891 Average: 1503.6 StdDev: 17317\nMin: 5 Max: 473238 Ignored: 0\n----------------------------------------------\n[      5,  23666) 143231  98.85%  98.85% ##########\n[  23666,  47328)    978   0.67%  99.53%\n[  47328,  70990)    206   0.14%  99.67%\n[  70990,  94651)     83   0.06%  99.73%\n[  94651, 118313)     14   0.01%  99.74%\n[ 118313, 141975)     17   0.01%  99.75%\n[ 141975, 165636)     34   0.02%  99.77%\n[ 165636, 189298)     22   0.02%  99.79%\n[ 189298, 212960)     10   0.01%  99.80%\n[ 212960, 236622)      6   0.00%  99.80%\n[ 236622, 260283)     25   0.02%  99.82%\n[ 260283, 283945)     10   0.01%  99.82%\n[ 283945, 307607)     35   0.02%  99.85%\n[ 307607, 331268)     31   0.02%  99.87%\n[ 331268, 354930)     21   0.01%  99.88%\n[ 354930, 378592)     60   0.04%  99.93%\n[ 378592, 402253)     23   0.02%  99.94%\n[ 402253, 425915)     29   0.02%  99.96%\n[ 425915, 449577)     36   0.02%  99.99%\n[ 449577, 473238]     20   0.01% 100.00%\n\nAttribute in nodes:\n\t46522 : flow_iat_mean [NUMERICAL]\n\t39806 : fwd_iat_min [NUMERICAL]\n\t38528 : flow_iat_min [NUMERICAL]\n\t19735 : bwd_pkt_len_std [NUMERICAL]\n\nAttribute in nodes with depth <= 0:\n\t233 : flow_iat_mean [NUMERICAL]\n\t41 : fwd_iat_min [NUMERICAL]\n\t26 : bwd_pkt_len_std [NUMERICAL]\n\nAttribute in nodes with depth <= 1:\n\t459 : flow_iat_mean [NUMERICAL]\n\t236 : bwd_pkt_len_std [NUMERICAL]\n\t144 : flow_iat_min [NUMERICAL]\n\t61 : fwd_iat_min [NUMERICAL]\n\nAttribute in nodes with depth <= 2:\n\t697 : bwd_pkt_len_std [NUMERICAL]\n\t689 : flow_iat_mean [NUMERICAL]\n\t402 : flow_iat_min [NUMERICAL]\n\t289 : fwd_iat_min [NUMERICAL]\n\nAttribute in nodes with depth <= 3:\n\t1325 : flow_iat_min [NUMERICAL]\n\t1185 : flow_iat_mean [NUMERICAL]\n\t1184 : bwd_pkt_len_std [NUMERICAL]\n\t630 : fwd_iat_min [NUMERICAL]\n\nAttribute in nodes with depth <= 5:\n\t3801 : flow_iat_mean [NUMERICAL]\n\t3759 : flow_iat_min [NUMERICAL]\n\t3362 : bwd_pkt_len_std [NUMERICAL]\n\t2552 : fwd_iat_min [NUMERICAL]\n\nCondition type in nodes:\n\t144591 : HigherCondition\nCondition type in nodes with depth <= 0:\n\t300 : HigherCondition\nCondition type in nodes with depth <= 1:\n\t900 : HigherCondition\nCondition type in nodes with depth <= 2:\n\t2077 : HigherCondition\nCondition type in nodes with depth <= 3:\n\t4324 : HigherCondition\nCondition type in nodes with depth <= 5:\n\t13474 : HigherCondition\nNode format: NOT_SET\n\nTraining OOB:\n\ttrees: 1, Out-of-bag evaluation: accuracy:0.998449 logloss:0.0559045\n\ttrees: 11, Out-of-bag evaluation: accuracy:0.998617 logloss:0.028687\n\ttrees: 21, Out-of-bag evaluation: accuracy:0.998712 logloss:0.0214437\n\ttrees: 31, Out-of-bag evaluation: accuracy:0.998757 logloss:0.018781\n\ttrees: 41, Out-of-bag evaluation: accuracy:0.998748 logloss:0.0175529\n\ttrees: 51, Out-of-bag evaluation: accuracy:0.998725 logloss:0.0168427\n\ttrees: 61, Out-of-bag evaluation: accuracy:0.998736 logloss:0.0162781\n\ttrees: 71, Out-of-bag evaluation: accuracy:0.998757 logloss:0.0159545\n\ttrees: 81, Out-of-bag evaluation: accuracy:0.998752 logloss:0.0158182\n\ttrees: 91, Out-of-bag evaluation: accuracy:0.998758 logloss:0.015413\n\ttrees: 101, Out-of-bag evaluation: accuracy:0.998762 logloss:0.0151109\n\ttrees: 111, Out-of-bag evaluation: accuracy:0.998774 logloss:0.0146609\n\ttrees: 121, Out-of-bag evaluation: accuracy:0.998762 logloss:0.0142258\n\ttrees: 131, Out-of-bag evaluation: accuracy:0.998769 logloss:0.0140478\n\ttrees: 141, Out-of-bag evaluation: accuracy:0.99878 logloss:0.013911\n\ttrees: 151, Out-of-bag evaluation: accuracy:0.998773 logloss:0.0138197\n\ttrees: 161, Out-of-bag evaluation: accuracy:0.99877 logloss:0.0135554\n\ttrees: 171, Out-of-bag evaluation: accuracy:0.998766 logloss:0.0133865\n\ttrees: 181, Out-of-bag evaluation: accuracy:0.998761 logloss:0.0132982\n\ttrees: 191, Out-of-bag evaluation: accuracy:0.998761 logloss:0.0131585\n\ttrees: 201, Out-of-bag evaluation: accuracy:0.998763 logloss:0.0131085\n\ttrees: 211, Out-of-bag evaluation: accuracy:0.998757 logloss:0.0129832\n\ttrees: 221, Out-of-bag evaluation: accuracy:0.998761 logloss:0.012893\n\ttrees: 231, Out-of-bag evaluation: accuracy:0.998762 logloss:0.012805\n\ttrees: 241, Out-of-bag evaluation: accuracy:0.998762 logloss:0.0128019\n\ttrees: 251, Out-of-bag evaluation: accuracy:0.998758 logloss:0.012632\n\ttrees: 261, Out-of-bag evaluation: accuracy:0.998761 logloss:0.0125415\n\ttrees: 271, Out-of-bag evaluation: accuracy:0.998759 logloss:0.0125395\n\ttrees: 281, Out-of-bag evaluation: accuracy:0.998759 logloss:0.0125021\n\ttrees: 291, Out-of-bag evaluation: accuracy:0.998758 logloss:0.0124639\n\ttrees: 300, Out-of-bag evaluation: accuracy:0.998759 logloss:0.0124152\n\n"
     ]
    }
   ],
   "source": [
    "# Erstellen einer Bilanz für das trainierte Modell\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 864x288 with 0 Axes>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Erstellen von Grafiken für die Effizienz des Trainings\n",
    "logs = model.make_inspector().training_logs()\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot([log.num_trees for log in logs], [log.evaluation.accuracy for log in logs])\n",
    "plt.xlabel(\"Number of trees\")\n",
    "plt.ylabel(\"Accuracy (out-of-bag)\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot([log.num_trees for log in logs], [log.evaluation.loss for log in logs])\n",
    "plt.xlabel(\"Number of trees\")\n",
    "plt.ylabel(\"Logloss (out-of-bag)\")\n",
    "\n",
    "plt.savefig('../Data/Visualized/GoldenEye_Model.png')\n",
    "plt.clf()"
   ]
  }
 ]
}